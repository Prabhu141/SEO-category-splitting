# -*- coding: utf-8 -*-
"""spliting category.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lnApe7kUKAV7ap9JA5uPu2Ey2RGMdJw-
"""

import requests
import pandas as pd
from bs4 import BeautifulSoup
import json

url = "https://www.ampledirectory.com/submit.php"
data = requests.get(url).text


soup = BeautifulSoup(data, 'html.parser')
# print(soup)


# Extract data from the parsed HTML and store in a list of dictionaries
options_list = []
options = soup.find_all('option')

for option in options:
    label = option.get('label')
    value = option.get('value')
    text = option.get_text(strip=True)

    options_list.append({
        'label': label,
        'value': value,
        'text': text
    })

# Convert the list to JSON format
json_output = json.dumps(options_list, indent=2)

# Save the JSON data to a file
with open('prolinkdirectory.json', 'w') as json_file:
    json_file.write(json_output)

print("JSON data has been saved to 'output.json'.")

import pandas as pd
import json

# Assuming your JSON data is stored in a file named 'input.json'
json_file = 'prolinkdirectory.json'

# Load JSON data
with open(json_file, 'r') as file:
    data = json.load(file)

# Flatten the JSON data using json_normalize
df = pd.json_normalize(data)

# Select only the columns 'label', 'value', and 'text'
df = df[['text']]

# Save the DataFrame to a CSV file named 'output.csv'
csv_file = 'prolinkdirectory.csv'
df.to_csv(csv_file, index=False)

print(f'Conversion successful. CSV file saved as {csv_file}')

import csv

# Specify the path to your CSV file
csv_file_path = 'prolinkdirectory.csv'

# Read data from the CSV file
with open(csv_file_path, newline='', encoding='utf-8') as csvfile:
    reader = csv.reader(csvfile)
    data = [row[0] for row in reader]

# Removing the specified symbols
cleaned_data = [line.replace("|___", "") for line in data]
# print(cleaned_data)

# Printing the cleaned data
for line in cleaned_data:
    print(line)

import csv

# Specify the path to your input CSV file
input_csv_file_path = 'prolinkdirectory.csv'

# Specify the path to your output CSV file
output_csv_file_path = 'cleaned_data.csv'

# Read data from the input CSV file
with open(input_csv_file_path, newline='', encoding='utf-8') as csvfile:
    reader = csv.reader(csvfile)
    data = [row[0] for row in reader]

# Removing the specified symbols
cleaned_data = [line.replace("|___", "") for line in data]

# Writing the cleaned data to a new CSV file
with open(output_csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile)
    for line in cleaned_data:
        writer.writerow([line])

print("Cleaned data has been saved to", output_csv_file_path)

import pandas as pd

# Read the CSV file
df = pd.read_csv('cleaned_data.csv')

# Print the column names to identify the correct ones
print(df.columns)

# Process the data
categories = {'Main Category': [], 'Subcategories': []}
current_main_category = None

# Replace 'Main Category' and 'Subcategories' with the correct column names
for index, row in df.iterrows():
    category = row['text'].strip()

    if '|' not in category:
        current_main_category = category
    else:
        subcategory = category.replace('|', '').strip()
        categories['Main Category'].append(current_main_category)
        categories['Subcategories'].append(subcategory)

# Create a new DataFrame
result_df = pd.DataFrame(categories)

# Save the result to a new CSV file
result_df.to_csv('sample.csv', index=False)

# Display the resulting DataFrame
print(result_df)

import pandas as pd

# Read the CSV file
df = pd.read_csv('sample.csv')

# Group by 'Main Category' and aggregate 'Subcategories' as a comma-separated string
result_df = df.groupby('Main Category')['Subcategories'].agg(', '.join).reset_index()

# Save the result to a new CSV file
result_df.to_csv('output.csv', index=False)

# Display the resulting DataFrame
print(result_df)